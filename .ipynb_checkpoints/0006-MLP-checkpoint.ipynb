{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化相关的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Model is ready.\n"
     ]
    }
   ],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 128\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "# def input and output\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# network model parameter\n",
    "weights = {\n",
    "    \"w1\": tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev = 0.1)),\n",
    "    \"w2\": tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev = 0.1)),\n",
    "    \"out_w\": tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev = 0.1))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b1\": tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"b2\": tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"out_b\": tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "print(\"Network Model is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights[\"w1\"]), _biases[\"b1\"]))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, _weights[\"w2\"]), _biases[\"b2\"]))\n",
    "    output = tf.matmul(layer_2, _weights[\"out_w\"]) + _biases[\"out_b\"]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function is ready.\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "pred = mlp(x, weights, biases)\n",
    "\n",
    "# cost and optimizer\n",
    "losses = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train_op = optimizer.minimize(losses)\n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "acc = tf.reduce_mean(tf.cast(corr, \"float\"))      # cast 来完成类型转换\n",
    "init_op = tf.global_variables_initializer()\n",
    "print(\"function is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005 / 020 cost: 1.4861\n",
      "training accuracy: 0.590\n",
      "test accuracy: 0.714\n",
      "Epoch: 010 / 020 cost: 0.7472\n",
      "training accuracy: 0.820\n",
      "test accuracy: 0.839\n",
      "Epoch: 015 / 020 cost: 0.5312\n",
      "training accuracy: 0.870\n",
      "test accuracy: 0.873\n",
      "Epoch: 020 / 020 cost: 0.4403\n",
      "training accuracy: 0.900\n",
      "test accuracy: 0.889\n",
      "Optimize had finished.\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 20     # 训练20个epoch\n",
    "batch_size = 100         #定义每批的样本数\n",
    "display_step = 5    \n",
    "# 运行计算图\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for epoch in range(1, training_epochs + 1, 1):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)     # batch 数\n",
    "        for i in range(1, total_batch + 1, 1):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feeds = {x: batch_xs, y: batch_ys}\n",
    "            sess.run(train_op, feed_dict = feeds)\n",
    "            avg_cost += sess.run(losses, feed_dict = feeds)\n",
    "        total_avg_cost = avg_cost / total_batch            # 完成每一个epoch的总的损失\n",
    "        # 每进行5个epoch就display\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch: %03d / %03d cost: %.4f\" % (epoch, training_epochs, total_avg_cost))\n",
    "            feeds = {x: batch_xs, y: batch_ys}\n",
    "            train_acc = sess.run(acc, feed_dict = feeds)\n",
    "            print(\"training accuracy: %.3f\" % (train_acc,))\n",
    "            feeds = {x: mnist.test.images, y: mnist.test.labels}\n",
    "            test_acc = sess.run(acc, feed_dict = feeds)\n",
    "            print(\"test accuracy: %.3f\" % (test_acc,))\n",
    "print(\"Optimize had finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
